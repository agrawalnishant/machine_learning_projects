{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model for Training, and Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import cPickle as pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# Config the matlotlib backend as plotting inline in IPython\n",
    "%matplotlib inline\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Deserialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (33402, 6) (33402, 64, 64)\n",
      "[[ 2.  0.  0.  0.  1.  9.]\n",
      " [ 2.  0.  0.  0.  2.  3.]]\n"
     ]
    }
   ],
   "source": [
    "train_pickle_file = 'SVHN_basic_train.pickle'\n",
    "\n",
    "with open(train_pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_labels = save['train_image_labels']\n",
    "  train_dataset = save['train_dataset']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_labels.shape, train_dataset.shape)\n",
    "print(train_labels[0:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set (13068, 6) (13068, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "test_pickle_file = 'SVHN_basic_test.pickle'\n",
    "\n",
    "with open(test_pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  test_labels = save['test_image_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Test set', test_labels.shape, test_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####TODO: Randomize and Shuffle\n",
    "####TODO: Use Boosting\n",
    "####TODO: Use Simulated Annealing / Decay\n",
    "\n",
    "###Reformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reformatted shapes of datasets\n",
      "\n",
      "train_dataset.shape: (33402, 64, 64, 1) , train_labels.shape: (33402, 6)\n",
      "test_dataset.shape: (13068, 64, 64, 1) , test_labels.shape: (13068, 6)\n"
     ]
    }
   ],
   "source": [
    "### Reformat dataset to 1 channel\n",
    "image_size=64\n",
    "num_channels=1 #greyscale\n",
    "\n",
    "def reformat(dataset):\n",
    "  dataset = dataset.reshape((-1, image_size, image_size, num_channels))\\\n",
    "        .astype(np.float32)\n",
    "  return dataset\n",
    "\n",
    "train_dataset = reformat(train_dataset)\n",
    "test_dataset = reformat(test_dataset)\n",
    "print(\"Reformatted shapes of datasets\\n\")\n",
    "print(\"train_dataset.shape:\",train_dataset.shape,\", train_labels.shape:\",train_labels.shape)\n",
    "print(\"test_dataset.shape:\", test_dataset.shape,\", test_labels.shape:\",test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    label_count=labels.shape[0]\n",
    "    #predictions=predictions.astype(int)\n",
    "    print(\"predictions:\\n\",predictions)\n",
    "    print(\"labels:\\n\", labels)\n",
    "    len_preds=np.argmax(predictions[0,:,:],axis=1)\n",
    "    digit_1_preds=np.argmax(predictions[1,:,:],axis=1)\n",
    "    digit_2_preds=np.argmax(predictions[2,:,:],axis=1)\n",
    "    digit_3_preds=np.argmax(predictions[3,:,:],axis=1)\n",
    "    digit_4_preds=np.argmax(predictions[4,:,:],axis=1)\n",
    "    digit_5_preds=np.argmax(predictions[5,:,:],axis=1)\n",
    "    \n",
    "    #print(\"len preds:\", len_preds)\n",
    "    #print(\" digit_1_preds\",digit_1_preds)\n",
    "    #print(\" digit_2_preds\",digit_2_preds)\n",
    "    #print(\" digit_3_preds\",digit_3_preds)\n",
    "    #print(\" digit_4_preds\",digit_4_preds)\n",
    "    #print(\" digit_5_preds\",digit_5_preds)\n",
    "    \n",
    "    len_accuracy=len_preds==labels[:,0]\n",
    "    #print(\"len_accuracy:\",len_accuracy.shape)\n",
    "    digit_1_accuracy=digit_1_preds==labels[:,1]\n",
    "    print(\"digit_1_accuracy:\",digit_1_accuracy.shape, digit_1_accuracy)\n",
    "    digit_2_accuracy=digit_2_preds==labels[:,2]\n",
    "    digit_3_accuracy=digit_3_preds==labels[:,3]\n",
    "    digit_4_accuracy=digit_4_preds==labels[:,4]\n",
    "    digit_5_accuracy=digit_1_preds==labels[:,5]\n",
    "    \n",
    "    \n",
    "    complete_accuracy=np.concatenate((len_accuracy.reshape(1,label_count),digit_1_accuracy.reshape(1,label_count),\\\n",
    "                                      digit_2_accuracy.reshape(1,label_count),digit_3_accuracy.reshape(1,label_count), \\\n",
    "                                      digit_4_accuracy.reshape(1,label_count),digit_5_accuracy.reshape(1,label_count)), axis=0).T\n",
    "    print(\"complete_accuracy:\\n\",complete_accuracy.shape, complete_accuracy)\n",
    "    return 100.0 * (np.sum([np.all(row) for row in complete_accuracy])) / len(labels)\n",
    "    #return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "    #      / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: (32, 64, 64, 1)\n",
      "hidden: (32, 64, 64, 8)\n",
      "h_pool2: (32, 32, 32, 8)\n",
      "h_pool3: (32, 16, 16, 8)\n",
      "reshape: Tensor(\"Reshape:0\", shape=(32, 2048), dtype=float32)\n",
      "tf_digit_masks: Tensor(\"Placeholder_2:0\", shape=(32, 10), dtype=float32) Tensor(\"Placeholder_3:0\", shape=(32, 10), dtype=float32) Tensor(\"Placeholder_4:0\", shape=(32, 10), dtype=float32) Tensor(\"Placeholder_5:0\", shape=(32, 10), dtype=float32) Tensor(\"Placeholder_6:0\", shape=(32, 10), dtype=float32)\n",
      "\n",
      "digit1_weights.shape:  (2048, 10)\n",
      "digit1_biases.shape:  (10,)\n",
      "logit_len: (32, 6)\n",
      "logit_digit_1: Tensor(\"mul:0\", shape=(32, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "patch_size = 5\n",
    "depth = 8\n",
    "num_hidden = 8\n",
    "num_labels = 10 # 10 for 0-9\n",
    "len_labels=6 # no digit, 5 for lenghts0-5, and >5\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, len_labels))\n",
    "  tf_digit_masks_1=tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_digit_masks_2=tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_digit_masks_3=tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_digit_masks_4=tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_digit_masks_5=tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  cnv_lyr1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.01))\n",
    "  cnv_lyr1_biases = tf.Variable(tf.constant(0.01, shape=[depth]))\n",
    "  cnv_lyr2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  cnv_lyr2_biases = tf.Variable(tf.constant(0.01, shape=[depth]))\n",
    "  cnv_lyr3_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, num_hidden], stddev=0.01))\n",
    "  cnv_lyr3_biases = tf.Variable(tf.constant(0.01, shape=[num_hidden]))\n",
    "  \n",
    "\n",
    "  length_weights = tf.Variable(tf.truncated_normal([num_hidden * depth * depth * 4, len_labels], stddev=0.1))\n",
    "  length_biases = tf.Variable(tf.constant(0.01, shape=[len_labels]))\n",
    "\n",
    "  digit1_weights = tf.Variable(tf.truncated_normal([num_hidden * depth * depth * 4, num_labels], stddev=0.1))\n",
    "  digit1_biases = tf.Variable(tf.constant(0.01, shape=[num_labels]))\n",
    "\n",
    "  digit2_weights = tf.Variable(tf.truncated_normal([num_hidden * depth * depth * 4, num_labels], stddev=0.1))\n",
    "  digit2_biases = tf.Variable(tf.constant(0.01, shape=[num_labels]))\n",
    "\n",
    "  digit3_weights = tf.Variable(tf.truncated_normal([num_hidden * depth * depth * 4, num_labels], stddev=0.1))\n",
    "  digit3_biases = tf.Variable(tf.constant(0.01, shape=[num_labels]))\n",
    "\n",
    "  digit4_weights = tf.Variable(tf.truncated_normal([num_hidden * depth * depth * 4, num_labels], stddev=0.1))\n",
    "  digit4_biases = tf.Variable(tf.constant(0.01, shape=[num_labels]))\n",
    "\n",
    "  digit5_weights = tf.Variable(tf.truncated_normal([num_hidden * depth * depth * 4, num_labels], stddev=0.1))\n",
    "  digit5_biases = tf.Variable(tf.constant(0.01, shape=[num_labels]))\n",
    "\n",
    "  def max_pool_2x2(x):\n",
    "     return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "  \n",
    "  # Model.\n",
    "  def model(data, digit_masks_1,digit_masks_2,digit_masks_3,digit_masks_4,digit_masks_5, is_train):\n",
    "    print(\"data:\",data.get_shape())\n",
    "    conv = tf.nn.conv2d(data, cnv_lyr1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + cnv_lyr1_biases)\n",
    "    #h_pool1 = max_pool_2x2(hidden)\n",
    "    print(\"hidden:\",hidden.get_shape())\n",
    "    \n",
    "    conv = tf.nn.conv2d(hidden, cnv_lyr2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + cnv_lyr2_biases)\n",
    "    h_pool2 = max_pool_2x2(hidden)\n",
    "    print(\"h_pool2:\",h_pool2.get_shape())\n",
    "\n",
    "    conv = tf.nn.conv2d(h_pool2, cnv_lyr3_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + cnv_lyr3_biases)\n",
    "    h_pool3 = max_pool_2x2(hidden)\n",
    "    print(\"h_pool3:\",h_pool3.get_shape())\n",
    "\n",
    "    shape = h_pool3.get_shape().as_list()\n",
    "    #print(\"shape:\",shape)\n",
    "    reshape = tf.reshape(h_pool3, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    \n",
    "    #digit_masks=(1-np.isnan(labels).astype(int))\n",
    "    #digit_masks=[(1-x) for x in labels if x != 'nan']\n",
    "    print(\"reshape:\", reshape)\n",
    "    print(\"tf_digit_masks:\", digit_masks_1,digit_masks_2,digit_masks_3,digit_masks_4,digit_masks_5)\n",
    "  \n",
    "    print()\n",
    "    logit_length = tf.matmul(reshape, length_weights) + length_biases\n",
    "    print(\"digit1_weights.shape: \",digit1_weights.get_shape())\n",
    "    print(\"digit1_biases.shape: \",digit1_biases.get_shape())\n",
    "\n",
    "    logit_1 = (tf.matmul(reshape, digit1_weights) + digit1_biases)*(digit_masks_1 if is_train==True else 1)\n",
    "    logit_2 = (tf.matmul(reshape, digit2_weights) + digit2_biases)*(digit_masks_2 if is_train==True else 1)\n",
    "    logit_3 = (tf.matmul(reshape, digit3_weights) + digit3_biases)*(digit_masks_3 if is_train==True else 1)\n",
    "    logit_4 = (tf.matmul(reshape, digit4_weights) + digit4_biases)*(digit_masks_4 if is_train==True else 1)\n",
    "    logit_5 = (tf.matmul(reshape, digit5_weights) + digit5_biases)*(digit_masks_5 if is_train==True else 1)\n",
    "    \n",
    "\n",
    "    return logit_length, logit_1,logit_2,logit_3,logit_4,logit_5\n",
    "  \n",
    "  # Training computation.\n",
    "  logit_len, logit_digit_1,logit_digit_2,logit_digit_3,logit_digit_4,logit_digit_5 \\\n",
    "    = model(tf_train_dataset, tf_digit_masks_1, tf_digit_masks_2, tf_digit_masks_3, tf_digit_masks_4, \\\n",
    "            tf_digit_masks_5, True)\n",
    "\n",
    "  loss_len     = tf.nn.sparse_softmax_cross_entropy_with_logits(logit_len, tf_train_labels[:,0])\n",
    "  loss_digit_1 = tf.nn.sparse_softmax_cross_entropy_with_logits(logit_digit_1, tf_train_labels[:,1])\n",
    "  loss_digit_2 = tf.nn.sparse_softmax_cross_entropy_with_logits(logit_digit_2, tf_train_labels[:,2])\n",
    "  loss_digit_3 = tf.nn.sparse_softmax_cross_entropy_with_logits(logit_digit_3, tf_train_labels[:,3])\n",
    "  loss_digit_4 = tf.nn.sparse_softmax_cross_entropy_with_logits(logit_digit_4, tf_train_labels[:,4])\n",
    "  loss_digit_5 = tf.nn.sparse_softmax_cross_entropy_with_logits(logit_digit_5, tf_train_labels[:,5])\n",
    "    \n",
    "  loss = tf.reduce_mean(loss_len + loss_digit_1 + loss_digit_2 + loss_digit_3 + loss_digit_4 + loss_digit_5)\n",
    "    \n",
    "    \n",
    "  # Optimizer.\n",
    "  global_step = tf.Variable(0, trainable=False)\n",
    "  starter_learning_rate = 0.1\n",
    "  learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                           1000, 0.99, staircase=True)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "  print(\"logit_len:\",logit_len.get_shape())\n",
    "  print(\"logit_digit_1:\",logit_digit_1)\n",
    "  # Predictions for the training, validation, and test data.\n",
    "  len_preds = tf.nn.softmax(logit_len)\n",
    "  train_prediction = tf.pack([ tf.nn.softmax(logit_digit_1),\n",
    "                               tf.nn.softmax(logit_digit_2),\n",
    "                               tf.nn.softmax(logit_digit_3),\n",
    "                               tf.nn.softmax(logit_digit_4),\n",
    "                               tf.nn.softmax(logit_digit_5)\n",
    "                             ])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create 5 mask arrays; 1 for each digit.\n",
    "# Each such Xth array will have all zeroes in Nth a row, if Xh digit is not present in Nth number in batch. \n",
    "def explode(batch_labels_arr):\n",
    "    batch_size_count=batch_labels_arr.shape[0]\n",
    "    target_col_count=10 # 10 labels for each digit\n",
    "    total_digits_cols=5\n",
    "    digit_mask_array = np.ndarray(shape=(total_digits_cols, batch_size_count, target_col_count),dtype=np.int32)\n",
    "    digit_mask_array[:,:,:]=int(0)\n",
    "    #print(\"batch_labels_arr: \\n\",batch_labels_arr)\n",
    "    #print(digit_mask_array.shape)\n",
    "    for row in range(batch_size_count):\n",
    "        len_val=batch_labels_arr[row,0].astype(int)\n",
    "        #print(\"len_val:\",len_val)\n",
    "        for counter in range(len_val):\n",
    "            digit_mask_array[5-counter-1, row, :] = 1\n",
    "    #print(\"digit_mask_array:\\n\",digit_mask_array)\n",
    "    return digit_mask_array[0,:,:],digit_mask_array[1,:,:],digit_mask_array[2,:,:],digit_mask_array[3,:,:],digit_mask_array[4,:,:],\n",
    "    \n",
    "#print(train_labels[10:20,:])        \n",
    "#explode(train_labels[10:20,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fetch argument array([[ 0.07392181,  0.23595174,  0.14960399,  0.19630623,  0.16388661,\n         0.18032964],\n       [ 0.01621046,  0.53119332,  0.10980991,  0.16294061,  0.08558007,\n         0.09426564],\n       [ 0.06673621,  0.18817003,  0.14459004,  0.20740102,  0.19588605,\n         0.19721663],\n       [ 0.04748308,  0.30701792,  0.16073528,  0.13410376,  0.22830814,\n         0.12235186],\n       [ 0.07233395,  0.16571948,  0.19650358,  0.22604053,  0.17328973,\n         0.16611271],\n       [ 0.09074324,  0.18743698,  0.13445902,  0.20395544,  0.17389323,\n         0.2095121 ],\n       [ 0.06162403,  0.20540282,  0.21601875,  0.18808298,  0.17593487,\n         0.15293655],\n       [ 0.05311203,  0.18847719,  0.14868075,  0.19192231,  0.16370773,\n         0.25409999],\n       [ 0.04374266,  0.21372427,  0.1352081 ,  0.17267683,  0.25232363,\n         0.18232451],\n       [ 0.05659232,  0.1243538 ,  0.05574917,  0.15806358,  0.26281127,\n         0.34242985],\n       [ 0.12010197,  0.16662383,  0.18205331,  0.21375024,  0.14982539,\n         0.16764523],\n       [ 0.04521446,  0.23332365,  0.10445648,  0.24945524,  0.2066595 ,\n         0.16089068],\n       [ 0.05667966,  0.2870537 ,  0.14804333,  0.1480308 ,  0.19160351,\n         0.16858901],\n       [ 0.03951617,  0.25685605,  0.11573061,  0.18464926,  0.19392386,\n         0.20932405],\n       [ 0.03894128,  0.19458419,  0.21687801,  0.24992998,  0.16084602,\n         0.13882044],\n       [ 0.03120749,  0.24050325,  0.18473397,  0.19642714,  0.17816131,\n         0.16896679],\n       [ 0.05496444,  0.27232566,  0.13128397,  0.22294773,  0.1559156 ,\n         0.16256259],\n       [ 0.03176567,  0.26558197,  0.30716047,  0.11870536,  0.18178838,\n         0.09499814],\n       [ 0.06553614,  0.18035583,  0.14996514,  0.18831728,  0.20130171,\n         0.21452388],\n       [ 0.11618735,  0.14271951,  0.1384618 ,  0.16951378,  0.20590079,\n         0.22721675],\n       [ 0.00787528,  0.45209688,  0.08072083,  0.20026092,  0.20442905,\n         0.05461705],\n       [ 0.04000654,  0.16093771,  0.13688208,  0.23968755,  0.14939089,\n         0.27309519],\n       [ 0.07921468,  0.16633731,  0.18720567,  0.20660692,  0.17607342,\n         0.18456203],\n       [ 0.06378552,  0.17952292,  0.07700883,  0.13488328,  0.31605795,\n         0.22874144],\n       [ 0.05825505,  0.2239566 ,  0.14391533,  0.16044967,  0.20732696,\n         0.20609646],\n       [ 0.03657535,  0.16150284,  0.10949775,  0.11034046,  0.28435674,\n         0.29772687],\n       [ 0.10344516,  0.17634563,  0.16138056,  0.17294131,  0.18594351,\n         0.19994384],\n       [ 0.04968575,  0.16966763,  0.1591755 ,  0.21909787,  0.19762444,\n         0.20474884],\n       [ 0.02125189,  0.25746804,  0.09375693,  0.23110273,  0.22343126,\n         0.17298914],\n       [ 0.07168052,  0.22160715,  0.08105965,  0.13337015,  0.19969828,\n         0.29258427],\n       [ 0.10661957,  0.12634271,  0.1100255 ,  0.16835056,  0.28615654,\n         0.20250511],\n       [ 0.06559201,  0.16871566,  0.14025451,  0.20177497,  0.21892846,\n         0.20473437]], dtype=float32) of array([[ 0.07392181,  0.23595174,  0.14960399,  0.19630623,  0.16388661,\n         0.18032964],\n       [ 0.01621046,  0.53119332,  0.10980991,  0.16294061,  0.08558007,\n         0.09426564],\n       [ 0.06673621,  0.18817003,  0.14459004,  0.20740102,  0.19588605,\n         0.19721663],\n       [ 0.04748308,  0.30701792,  0.16073528,  0.13410376,  0.22830814,\n         0.12235186],\n       [ 0.07233395,  0.16571948,  0.19650358,  0.22604053,  0.17328973,\n         0.16611271],\n       [ 0.09074324,  0.18743698,  0.13445902,  0.20395544,  0.17389323,\n         0.2095121 ],\n       [ 0.06162403,  0.20540282,  0.21601875,  0.18808298,  0.17593487,\n         0.15293655],\n       [ 0.05311203,  0.18847719,  0.14868075,  0.19192231,  0.16370773,\n         0.25409999],\n       [ 0.04374266,  0.21372427,  0.1352081 ,  0.17267683,  0.25232363,\n         0.18232451],\n       [ 0.05659232,  0.1243538 ,  0.05574917,  0.15806358,  0.26281127,\n         0.34242985],\n       [ 0.12010197,  0.16662383,  0.18205331,  0.21375024,  0.14982539,\n         0.16764523],\n       [ 0.04521446,  0.23332365,  0.10445648,  0.24945524,  0.2066595 ,\n         0.16089068],\n       [ 0.05667966,  0.2870537 ,  0.14804333,  0.1480308 ,  0.19160351,\n         0.16858901],\n       [ 0.03951617,  0.25685605,  0.11573061,  0.18464926,  0.19392386,\n         0.20932405],\n       [ 0.03894128,  0.19458419,  0.21687801,  0.24992998,  0.16084602,\n         0.13882044],\n       [ 0.03120749,  0.24050325,  0.18473397,  0.19642714,  0.17816131,\n         0.16896679],\n       [ 0.05496444,  0.27232566,  0.13128397,  0.22294773,  0.1559156 ,\n         0.16256259],\n       [ 0.03176567,  0.26558197,  0.30716047,  0.11870536,  0.18178838,\n         0.09499814],\n       [ 0.06553614,  0.18035583,  0.14996514,  0.18831728,  0.20130171,\n         0.21452388],\n       [ 0.11618735,  0.14271951,  0.1384618 ,  0.16951378,  0.20590079,\n         0.22721675],\n       [ 0.00787528,  0.45209688,  0.08072083,  0.20026092,  0.20442905,\n         0.05461705],\n       [ 0.04000654,  0.16093771,  0.13688208,  0.23968755,  0.14939089,\n         0.27309519],\n       [ 0.07921468,  0.16633731,  0.18720567,  0.20660692,  0.17607342,\n         0.18456203],\n       [ 0.06378552,  0.17952292,  0.07700883,  0.13488328,  0.31605795,\n         0.22874144],\n       [ 0.05825505,  0.2239566 ,  0.14391533,  0.16044967,  0.20732696,\n         0.20609646],\n       [ 0.03657535,  0.16150284,  0.10949775,  0.11034046,  0.28435674,\n         0.29772687],\n       [ 0.10344516,  0.17634563,  0.16138056,  0.17294131,  0.18594351,\n         0.19994384],\n       [ 0.04968575,  0.16966763,  0.1591755 ,  0.21909787,  0.19762444,\n         0.20474884],\n       [ 0.02125189,  0.25746804,  0.09375693,  0.23110273,  0.22343126,\n         0.17298914],\n       [ 0.07168052,  0.22160715,  0.08105965,  0.13337015,  0.19969828,\n         0.29258427],\n       [ 0.10661957,  0.12634271,  0.1100255 ,  0.16835056,  0.28615654,\n         0.20250511],\n       [ 0.06559201,  0.16871566,  0.14025451,  0.20177497,  0.21892846,\n         0.20473437]], dtype=float32) has invalid type <type 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-38cb0bd3729a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtf_train_dataset\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_train_labels\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_digit_masks_1\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdigit_1_mask\u001b[0m \u001b[0;34m,\u001b[0m                \u001b[0mtf_digit_masks_2\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdigit_2_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_digit_masks_3\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdigit_3_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_digit_masks_4\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdigit_4_mask\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mtf_digit_masks_5\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdigit_5_mask\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     _, l, len_predictions, predictions = session.run(\n\u001b[0;32m---> 17\u001b[0;31m       [optimizer, loss, len_preds, train_prediction], feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Minibatch loss at step %d: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/_root_nishi/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 340\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/_root_nishi/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;31m# Validate and process fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m     \u001b[0mprocessed_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0munique_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessed_fetches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0mtarget_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessed_fetches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/_root_nishi/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_process_fetches\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    491\u001b[0m           raise TypeError('Fetch argument %r of %r has invalid type %r, '\n\u001b[1;32m    492\u001b[0m                           \u001b[0;34m'must be a string or Tensor. (%s)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                           % (subfetch, fetch, type(subfetch), str(e)))\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m           raise ValueError('Fetch argument %r of %r cannot be interpreted as a '\n",
      "\u001b[0;31mTypeError\u001b[0m: Fetch argument array([[ 0.07392181,  0.23595174,  0.14960399,  0.19630623,  0.16388661,\n         0.18032964],\n       [ 0.01621046,  0.53119332,  0.10980991,  0.16294061,  0.08558007,\n         0.09426564],\n       [ 0.06673621,  0.18817003,  0.14459004,  0.20740102,  0.19588605,\n         0.19721663],\n       [ 0.04748308,  0.30701792,  0.16073528,  0.13410376,  0.22830814,\n         0.12235186],\n       [ 0.07233395,  0.16571948,  0.19650358,  0.22604053,  0.17328973,\n         0.16611271],\n       [ 0.09074324,  0.18743698,  0.13445902,  0.20395544,  0.17389323,\n         0.2095121 ],\n       [ 0.06162403,  0.20540282,  0.21601875,  0.18808298,  0.17593487,\n         0.15293655],\n       [ 0.05311203,  0.18847719,  0.14868075,  0.19192231,  0.16370773,\n         0.25409999],\n       [ 0.04374266,  0.21372427,  0.1352081 ,  0.17267683,  0.25232363,\n         0.18232451],\n       [ 0.05659232,  0.1243538 ,  0.05574917,  0.15806358,  0.26281127,\n         0.34242985],\n       [ 0.12010197,  0.16662383,  0.18205331,  0.21375024,  0.14982539,\n         0.16764523],\n       [ 0.04521446,  0.23332365,  0.10445648,  0.24945524,  0.2066595 ,\n         0.16089068],\n       [ 0.05667966,  0.2870537 ,  0.14804333,  0.1480308 ,  0.19160351,\n         0.16858901],\n       [ 0.03951617,  0.25685605,  0.11573061,  0.18464926,  0.19392386,\n         0.20932405],\n       [ 0.03894128,  0.19458419,  0.21687801,  0.24992998,  0.16084602,\n         0.13882044],\n       [ 0.03120749,  0.24050325,  0.18473397,  0.19642714,  0.17816131,\n         0.16896679],\n       [ 0.05496444,  0.27232566,  0.13128397,  0.22294773,  0.1559156 ,\n         0.16256259],\n       [ 0.03176567,  0.26558197,  0.30716047,  0.11870536,  0.18178838,\n         0.09499814],\n       [ 0.06553614,  0.18035583,  0.14996514,  0.18831728,  0.20130171,\n         0.21452388],\n       [ 0.11618735,  0.14271951,  0.1384618 ,  0.16951378,  0.20590079,\n         0.22721675],\n       [ 0.00787528,  0.45209688,  0.08072083,  0.20026092,  0.20442905,\n         0.05461705],\n       [ 0.04000654,  0.16093771,  0.13688208,  0.23968755,  0.14939089,\n         0.27309519],\n       [ 0.07921468,  0.16633731,  0.18720567,  0.20660692,  0.17607342,\n         0.18456203],\n       [ 0.06378552,  0.17952292,  0.07700883,  0.13488328,  0.31605795,\n         0.22874144],\n       [ 0.05825505,  0.2239566 ,  0.14391533,  0.16044967,  0.20732696,\n         0.20609646],\n       [ 0.03657535,  0.16150284,  0.10949775,  0.11034046,  0.28435674,\n         0.29772687],\n       [ 0.10344516,  0.17634563,  0.16138056,  0.17294131,  0.18594351,\n         0.19994384],\n       [ 0.04968575,  0.16966763,  0.1591755 ,  0.21909787,  0.19762444,\n         0.20474884],\n       [ 0.02125189,  0.25746804,  0.09375693,  0.23110273,  0.22343126,\n         0.17298914],\n       [ 0.07168052,  0.22160715,  0.08105965,  0.13337015,  0.19969828,\n         0.29258427],\n       [ 0.10661957,  0.12634271,  0.1100255 ,  0.16835056,  0.28615654,\n         0.20250511],\n       [ 0.06559201,  0.16871566,  0.14025451,  0.20177497,  0.21892846,\n         0.20473437]], dtype=float32) of array([[ 0.07392181,  0.23595174,  0.14960399,  0.19630623,  0.16388661,\n         0.18032964],\n       [ 0.01621046,  0.53119332,  0.10980991,  0.16294061,  0.08558007,\n         0.09426564],\n       [ 0.06673621,  0.18817003,  0.14459004,  0.20740102,  0.19588605,\n         0.19721663],\n       [ 0.04748308,  0.30701792,  0.16073528,  0.13410376,  0.22830814,\n         0.12235186],\n       [ 0.07233395,  0.16571948,  0.19650358,  0.22604053,  0.17328973,\n         0.16611271],\n       [ 0.09074324,  0.18743698,  0.13445902,  0.20395544,  0.17389323,\n         0.2095121 ],\n       [ 0.06162403,  0.20540282,  0.21601875,  0.18808298,  0.17593487,\n         0.15293655],\n       [ 0.05311203,  0.18847719,  0.14868075,  0.19192231,  0.16370773,\n         0.25409999],\n       [ 0.04374266,  0.21372427,  0.1352081 ,  0.17267683,  0.25232363,\n         0.18232451],\n       [ 0.05659232,  0.1243538 ,  0.05574917,  0.15806358,  0.26281127,\n         0.34242985],\n       [ 0.12010197,  0.16662383,  0.18205331,  0.21375024,  0.14982539,\n         0.16764523],\n       [ 0.04521446,  0.23332365,  0.10445648,  0.24945524,  0.2066595 ,\n         0.16089068],\n       [ 0.05667966,  0.2870537 ,  0.14804333,  0.1480308 ,  0.19160351,\n         0.16858901],\n       [ 0.03951617,  0.25685605,  0.11573061,  0.18464926,  0.19392386,\n         0.20932405],\n       [ 0.03894128,  0.19458419,  0.21687801,  0.24992998,  0.16084602,\n         0.13882044],\n       [ 0.03120749,  0.24050325,  0.18473397,  0.19642714,  0.17816131,\n         0.16896679],\n       [ 0.05496444,  0.27232566,  0.13128397,  0.22294773,  0.1559156 ,\n         0.16256259],\n       [ 0.03176567,  0.26558197,  0.30716047,  0.11870536,  0.18178838,\n         0.09499814],\n       [ 0.06553614,  0.18035583,  0.14996514,  0.18831728,  0.20130171,\n         0.21452388],\n       [ 0.11618735,  0.14271951,  0.1384618 ,  0.16951378,  0.20590079,\n         0.22721675],\n       [ 0.00787528,  0.45209688,  0.08072083,  0.20026092,  0.20442905,\n         0.05461705],\n       [ 0.04000654,  0.16093771,  0.13688208,  0.23968755,  0.14939089,\n         0.27309519],\n       [ 0.07921468,  0.16633731,  0.18720567,  0.20660692,  0.17607342,\n         0.18456203],\n       [ 0.06378552,  0.17952292,  0.07700883,  0.13488328,  0.31605795,\n         0.22874144],\n       [ 0.05825505,  0.2239566 ,  0.14391533,  0.16044967,  0.20732696,\n         0.20609646],\n       [ 0.03657535,  0.16150284,  0.10949775,  0.11034046,  0.28435674,\n         0.29772687],\n       [ 0.10344516,  0.17634563,  0.16138056,  0.17294131,  0.18594351,\n         0.19994384],\n       [ 0.04968575,  0.16966763,  0.1591755 ,  0.21909787,  0.19762444,\n         0.20474884],\n       [ 0.02125189,  0.25746804,  0.09375693,  0.23110273,  0.22343126,\n         0.17298914],\n       [ 0.07168052,  0.22160715,  0.08105965,  0.13337015,  0.19969828,\n         0.29258427],\n       [ 0.10661957,  0.12634271,  0.1100255 ,  0.16835056,  0.28615654,\n         0.20250511],\n       [ 0.06559201,  0.16871566,  0.14025451,  0.20177497,  0.21892846,\n         0.20473437]], dtype=float32) has invalid type <type 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "num_steps = 100001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    #print(\"offset:\", offset)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :,:]\n",
    "    #print(\"batch_data:\",batch_data.shape)\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :].astype(int)\n",
    "    digit_1_mask, digit_2_mask,digit_3_mask,digit_4_mask,digit_5_mask = explode(batch_labels)\n",
    "    #batch_masks=np.array([item == item for item in batch_labels]).astype(int)\n",
    "    #print(\"digit_5_mask:\",digit_5_mask)\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, tf_digit_masks_1 : digit_1_mask ,\\\n",
    "                tf_digit_masks_2 : digit_2_mask, tf_digit_masks_3 : digit_3_mask, tf_digit_masks_4 : digit_4_mask, \\\n",
    "                tf_digit_masks_5 : digit_5_mask}\n",
    "    _, l, len_predictions, predictions = session.run(\n",
    "      [optimizer, loss, len_preds, train_prediction], feed_dict=feed_dict)\n",
    "    if (step > 1 and step % 10000 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "     # print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
